{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d94bfc0ecc2f8b2",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5cb70fce7684d1e9",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-13T11:48:30.089444Z",
     "start_time": "2024-01-13T11:48:29.191273Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9182fae9384e3c0",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-13T11:48:30.094225Z",
     "start_time": "2024-01-13T11:48:30.090354Z"
    }
   },
   "outputs": [],
   "source": [
    "# load english stopwords\n",
    "stopwords = stopwords.words (\"english\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f72da6a7eb48f3",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Part 1 - Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c3923ba78c9f7a",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## a. News Headlines Text Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc360e55a140326",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87db3ce06ca5459e",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-13T11:48:33.391343Z",
     "start_time": "2024-01-13T11:48:33.310871Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records:  47146\n"
     ]
    }
   ],
   "source": [
    "data_file_path = 'NewsCategoryDataset_2017_2022.json'\n",
    "with open(data_file_path, 'r') as file:\n",
    "    # remove new lines at the end of the file\n",
    "    file = file.read().strip() \n",
    "    # wrapping the json elements in an array to be able to load them\n",
    "    file_content = '[' + ','.join(file.split('\\n')) + ']' \n",
    "    # load data\n",
    "    json_records = json.loads(file_content)\n",
    "print('Number of records: ', len(json_records))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b59096f4ef462dd",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Extract texts from records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d1bce4c111c1a9a",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-13T11:48:36.724764Z",
     "start_time": "2024-01-13T11:48:36.721255Z"
    }
   },
   "outputs": [],
   "source": [
    "# Extract headlines\n",
    "headlines = [record['headline'] for record in json_records]\n",
    "# Extract short descriptions\n",
    "short_descriptions = [record['short_description'] for record in json_records]\n",
    "# Combine headlines and short descriptions\n",
    "headline_desc = [head + ' ' + desc for head, desc in zip(headlines, short_descriptions)]\n",
    "# Extract categories\n",
    "categories = [record['category'] for record in json_records]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4697d89367051618",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Preprocess texts\n",
    "This function takes a text and returns a list of tokens after removing stopwords, punctuations, and numbers, and stemming the tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5bcaa0d1fa92980",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-13T11:48:39.824217Z",
     "start_time": "2024-01-13T11:48:39.820126Z"
    }
   },
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    # lowercase and tokenize\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    stemmer = PorterStemmer()\n",
    "    # Remove stopwords, punctuations, and numbers, and stem the tokens and return them\n",
    "    return [stemmer.stem(word) for word in tokens if word.isalpha() and word not in stopwords] \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2e26f886f76180",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-13T11:49:00.089503Z",
     "start_time": "2024-01-13T11:48:40.700562Z"
    }
   },
   "outputs": [],
   "source": [
    "# Preprocess headlines, short descriptions, and combined texts\n",
    "headlines_processed = [preprocess_text(headline) for headline in headlines]\n",
    "short_descriptions_processed = [preprocess_text(short_description) for short_description in short_descriptions]\n",
    "headline_desc_processed = [preprocess_text(headline_desc) for headline_desc in headline_desc]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56edac77bdb3464e",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## b. Terms weights using TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db71f5f50cefab5",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Term Frequency (TF)\n",
    "This function takes a document and returns a dictionary of terms and their normalized frequencies in the document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "88dd6b567a0e7bf2",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-13T11:49:00.092039Z",
     "start_time": "2024-01-13T11:49:00.090188Z"
    }
   },
   "outputs": [],
   "source": [
    "def doc_term_freq(doc):\n",
    "    # Compute term frequency for each term in the document\n",
    "    terms_freq = Counter(doc)\n",
    "    # get the maximum term frequency to normalize the term frequency\n",
    "    max_freq = max(terms_freq.values()) if len(terms_freq) > 0 else 0\n",
    "    # Normalize term frequency\n",
    "    for i in terms_freq:\n",
    "        terms_freq[i] = terms_freq[i] / (max_freq * len(doc))\n",
    "    return terms_freq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19130bee68c2073d",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Inverse Document Frequency (IDF)\n",
    "This function takes a list of documents and returns the IDF value of the terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "84431f1a84919c30",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-13T11:49:00.095498Z",
     "start_time": "2024-01-13T11:49:00.092833Z"
    }
   },
   "outputs": [],
   "source": [
    "def inverse_doc_freq(docs, term_set):\n",
    "    idf_values = {}\n",
    "    docs_freq = Counter([term for doc in docs for term in set(doc)])\n",
    "    docs_len = len(docs)\n",
    "    for term in term_set:\n",
    "        idf_values[term] = math.log(docs_len / docs_freq[term])\n",
    "    return idf_values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "980f0745e400a5ba",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### TF-IDF matrix\n",
    "This function takes a list of documents and returns a TF-IDF matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "56f42c6b817f499c",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-13T11:49:00.103080Z",
     "start_time": "2024-01-13T11:49:00.097494Z"
    }
   },
   "outputs": [],
   "source": [
    "def tfidf_matrix(docs):\n",
    "    # Get the set of terms in all documents\n",
    "    term_set = set(term for doc in docs for term in doc)\n",
    "    # Initialize TF-IDF matrix with zeros\n",
    "    tfidf_matrix = pd.DataFrame(0.0, index=range(len(docs)), columns=list(term_set))\n",
    "    # Compute IDF for each term\n",
    "    idf_values = inverse_doc_freq(docs, term_set)   \n",
    "    # Compute TF for each term in each document\n",
    "    tf_values = {doc_idx: doc_term_freq(doc) for doc_idx, doc in enumerate(docs)}\n",
    "    # Compute TF-IDF for each term in each document\n",
    "    for term in term_set:\n",
    "        tf = [tf_values[doc_idx][term] * idf_values[term] if term in tf_values[doc_idx].keys() else 0 for doc_idx in range(len(docs))]\n",
    "        tfidf_matrix.loc[:, term] = tf \n",
    "    return tfidf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e9bcf269010f3f",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Compute TF-IDF matrix for the headlines and short descriptions combined texts\n",
    "headlines_desc_tfidf = tfidf_matrix(headline_desc_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fe490ca7ffd7613e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-11T05:25:51.115639Z",
     "start_time": "2024-01-11T05:18:01.824973Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Export TF-IDF matrix to csv because it takes a long time to compute\n",
    "headlines_desc_tfidf.to_csv('headlines_desc_tfidf.csv')"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Load TF-IDF matrix from csv\n",
    "headlines_desc_tfidf = pd.read_csv('headlines_desc_tfidf.csv', index_col=0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-13T11:53:21.022922Z",
     "start_time": "2024-01-13T11:50:03.906172Z"
    }
   },
   "id": "ea42a4ea5f1cc6e4",
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "id": "5d1afc5fb7a091d8",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Highest weighted n% of the terms per document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9831ba34a85f870b",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-13T11:55:26.644920Z",
     "start_time": "2024-01-13T11:55:26.639379Z"
    }
   },
   "outputs": [],
   "source": [
    "# Extract top n% highest-weighted terms from a document (row), return a list of tuples (term, weight)\n",
    "def extract_top_terms(row, percentage):\n",
    "    # Get the number of terms to extract, a minimum of 20 terms or n% of the terms in the document\n",
    "    num_terms = min(20, int(len(row) * percentage / 100))\n",
    "    # Sort terms by their weights in descending order and get the top num_terms terms\n",
    "    top_terms = row.sort_values(ascending=False).head(num_terms)\n",
    "    # Get the terms in a list\n",
    "    terms =  top_terms.index.tolist()\n",
    "    # Get the weights in a list\n",
    "    weights = top_terms.tolist()\n",
    "    # Return a list of tuples (term, weight)\n",
    "    return [(t, w) for t, w in zip(terms, weights)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4b48522af27a5391",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-13T11:56:10.699830Z",
     "start_time": "2024-01-13T11:55:27.314777Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get top n% terms from each document\n",
    "n = 0.1 \n",
    "# Creating a dictionary where each key is a document and each value is a list of top n% terms\n",
    "document_terms = {doc_id: extract_top_terms(row, n) for doc_id, row in headlines_desc_tfidf.iterrows()}\n",
    "# Prepare json Output\n",
    "docs_detail = {\n",
    "    doc: {\n",
    "        'headline': json_records[doc]['headline'],\n",
    "        'short_description': json_records[doc]['short_description'],\n",
    "        'category': json_records[doc]['category'],\n",
    "        'link': json_records[doc]['link'],\n",
    "        'date': json_records[doc]['date'],\n",
    "        'authors': json_records[doc]['authors'],\n",
    "        'keywords': document_terms[doc]\n",
    "    } for doc in document_terms.keys()\n",
    "}\n",
    "\n",
    "# Export to json\n",
    "with open('./static/data/docs_details.json', 'w') as f:\n",
    "    json.dump(docs_detail, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d1c14d383334da5",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## c. Highest weighted n% of the terms per category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7b7a51f6efa0cea9",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-13T11:57:59.518150Z",
     "start_time": "2024-01-13T11:56:10.708722Z"
    }
   },
   "outputs": [],
   "source": [
    "# Compute average term weights for each category\n",
    "category_avg_term_weights = {}\n",
    "for category in set(categories):\n",
    "    headlines_indices = [i for i, x in enumerate(categories) if x == category]\n",
    "    category_avg_term_weights[category] = {term: headlines_desc_tfidf.loc[headlines_indices, term].mean() for term in headlines_desc_tfidf.columns}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "86c0f682a6a6cb88",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-13T11:57:59.990122Z",
     "start_time": "2024-01-13T11:57:59.513462Z"
    }
   },
   "outputs": [],
   "source": [
    "# get top n% terms from each category\n",
    "n = 3\n",
    "# Creating a dictionary where each key is a category and each value is a list of top n% terms\n",
    "category_terms = {}\n",
    "for category, term_weights in category_avg_term_weights.items():\n",
    "    sorted_terms = sorted(term_weights.items(), key=lambda x: x[1], reverse=True)\n",
    "    top_terms = sorted_terms[:int(len(sorted_terms) * n / 100)]\n",
    "    category_terms[category] = top_terms\n",
    "\n",
    "# Prepare json Output\n",
    "category_details = {\n",
    "    category: {\n",
    "        'articles': [d for d in json_records if d['category'] == category],\n",
    "        'keywords': category_terms[category]\n",
    "    } for category in category_terms.keys()\n",
    "}\n",
    "\n",
    "# Export to json\n",
    "with open('./static/data/category_details.json', 'w') as f:\n",
    "    json.dump(category_details, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a56a24ceb90a142",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## d. K-means clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d22cd39ad7004384",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Cosine similarity\n",
    "This function takes two arrays and returns the cosine similarity between the vectors represented by the arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "183e5b53af7dc829",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-13T11:57:59.993608Z",
     "start_time": "2024-01-13T11:57:59.991060Z"
    }
   },
   "outputs": [],
   "source": [
    "def cos_sim(doc1, doc2):\n",
    "    # compute the norm of each document and divide each document by its norm\n",
    "    doc1_norm = doc1 / np.linalg.norm(doc1, axis=1)[:, np.newaxis]\n",
    "    doc2_norm = doc2 / np.linalg.norm(doc2, axis=1)[:, np.newaxis]\n",
    "    # compute the dot product between the documents to get the cosine similarity\n",
    "    return np.dot(doc1_norm, doc2_norm.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c22a8051bb61513",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### K-means clustering\n",
    "This function takes a dataframe and the number of clusters and returns the clusters of the documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3c5dc82d9801d4a2",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-13T11:57:59.996408Z",
     "start_time": "2024-01-13T11:57:59.994004Z"
    }
   },
   "outputs": [],
   "source": [
    "def k_means(df, k):\n",
    "    # Initialize centroids with k random documents\n",
    "    centroids = df.sample(n=k).values\n",
    "    # Convert dataframe to numpy array\n",
    "    values = df.values\n",
    "    for iter in range(100):\n",
    "        print(\"Iteration: \", iter)\n",
    "        # Compute cosine similarity between each document and each centroid\n",
    "        sim_scores = cos_sim(values, centroids)\n",
    "        # Assign each document to the cluster of the centroid with the highest similarity\n",
    "        clusters = np.argmax(sim_scores, axis=1)\n",
    "        # If the clusters didn't change, stop\n",
    "        if 'Cluster' in df.columns and all(df['Cluster'].eq(clusters)):\n",
    "            break\n",
    "        # Update centroids\n",
    "        df['Cluster'] = clusters\n",
    "        # Compute new centroids\n",
    "        centroids = np.array([values[clusters == i].mean(axis=0) for i in range(k)])\n",
    "    return clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6c9f2171b27cbc8",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-13T12:27:38.344759Z",
     "start_time": "2024-01-13T11:57:59.996095Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  0\n",
      "Iteration:  1\n",
      "Iteration:  2\n",
      "Iteration:  3\n",
      "Iteration:  4\n",
      "Iteration:  5\n",
      "Iteration:  6\n",
      "Iteration:  7\n",
      "Iteration:  8\n",
      "Iteration:  9\n",
      "Iteration:  10\n",
      "Iteration:  11\n",
      "Iteration:  12\n",
      "Iteration:  13\n",
      "Iteration:  14\n",
      "Iteration:  15\n",
      "Iteration:  16\n",
      "Iteration:  17\n",
      "Iteration:  18\n",
      "Iteration:  19\n",
      "Iteration:  20\n",
      "Iteration:  21\n",
      "Iteration:  22\n",
      "Iteration:  23\n",
      "Iteration:  24\n",
      "Iteration:  25\n",
      "Iteration:  26\n",
      "Iteration:  27\n",
      "Iteration:  28\n",
      "Iteration:  29\n",
      "Iteration:  30\n",
      "Iteration:  31\n",
      "Iteration:  32\n",
      "Iteration:  33\n",
      "Iteration:  34\n",
      "Iteration:  35\n",
      "Iteration:  36\n",
      "Iteration:  37\n",
      "Iteration:  38\n",
      "Iteration:  39\n",
      "Iteration:  40\n",
      "Iteration:  41\n",
      "Iteration:  42\n",
      "Iteration:  43\n",
      "Iteration:  44\n",
      "Iteration:  45\n",
      "Iteration:  46\n",
      "Iteration:  47\n",
      "Iteration:  48\n",
      "Iteration:  49\n",
      "Iteration:  50\n",
      "Iteration:  51\n",
      "Iteration:  52\n",
      "Iteration:  53\n",
      "Iteration:  54\n",
      "Iteration:  55\n",
      "Iteration:  56\n",
      "Iteration:  57\n",
      "Iteration:  58\n",
      "Iteration:  59\n",
      "Iteration:  60\n",
      "Iteration:  61\n",
      "Iteration:  62\n",
      "Iteration:  63\n",
      "Iteration:  64\n",
      "Iteration:  65\n",
      "Iteration:  66\n",
      "Iteration:  67\n",
      "Iteration:  68\n",
      "Iteration:  69\n",
      "Iteration:  70\n",
      "Iteration:  71\n",
      "Iteration:  72\n",
      "Iteration:  73\n",
      "Iteration:  74\n",
      "Iteration:  75\n",
      "Iteration:  76\n",
      "Iteration:  77\n",
      "Iteration:  78\n",
      "Iteration:  79\n",
      "Iteration:  80\n",
      "Iteration:  81\n",
      "Iteration:  82\n",
      "Iteration:  83\n",
      "Iteration:  84\n",
      "Iteration:  85\n",
      "Iteration:  86\n",
      "Iteration:  87\n",
      "Iteration:  88\n",
      "Iteration:  89\n",
      "Iteration:  90\n"
     ]
    }
   ],
   "source": [
    "data = headlines_desc_tfidf.copy()\n",
    "clusters = k_means(data, 41)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f15d1c9a9504ddc9",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## e. Highest weighted n% of the terms per cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8262170fe2f68bb2",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-13T12:29:28.759289Z",
     "start_time": "2024-01-13T12:27:38.349363Z"
    }
   },
   "outputs": [],
   "source": [
    "# Compute average term weights for each cluster\n",
    "cluster_avg_term_weights = {}\n",
    "clust_indices = {}\n",
    "for cluster in set(clusters):\n",
    "    headlines_indices = [i for i, x in enumerate(clusters) if x == cluster]\n",
    "    clust_indices[cluster] = headlines_indices\n",
    "    cluster_avg_term_weights[cluster] = {term: headlines_desc_tfidf.loc[headlines_indices, term].mean() for term in headlines_desc_tfidf.columns}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "24aee2a9b9866927",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-13T12:29:29.201394Z",
     "start_time": "2024-01-13T12:29:28.828524Z"
    }
   },
   "outputs": [],
   "source": [
    "# get top n% terms from each cluster\n",
    "n = 3\n",
    "# Creating a dictionary where each key is a cluster and each value is a list of top n% terms\n",
    "cluster_terms = {}\n",
    "for cluster, term_weights in cluster_avg_term_weights.items():\n",
    "    sorted_terms = sorted(term_weights.items(), key=lambda x: x[1], reverse=True)\n",
    "    top_terms = sorted_terms[:int(len(sorted_terms) * n / 100)]\n",
    "    cluster_terms[cluster] = top_terms\n",
    "\n",
    "# Prepare json Output\n",
    "cluster_details = {\n",
    "    int(cluster): {\n",
    "        'articles': [json_records[i] for i in clust_indices[cluster]],\n",
    "        'keywords': cluster_terms[cluster]\n",
    "    } for cluster in cluster_terms.keys()\n",
    "}\n",
    "\n",
    "# Export to json\n",
    "with open('./static/data/cluster_details.json', 'w') as f:\n",
    "    json.dump(cluster_details, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f458d15ddb9ccef",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Part 2 - Web Application"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f65ffd1fb5a3c6",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "To run the web application, run the following cell or copy it to the terminal and run it and then open http://localhost:5001/ in the browser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "292071c6763aa483",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-13T12:39:16.695221Z",
     "start_time": "2024-01-13T12:29:29.201431Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app 'flask_app.py'\r\n",
      " * Debug mode: off\r\n",
      "\u001B[31m\u001B[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001B[0m\r\n",
      " * Running on http://127.0.0.1:5001\r\n",
      "\u001B[33mPress CTRL+C to quit\u001B[0m\r\n",
      "127.0.0.1 - - [13/Jan/2024 13:33:56] \"GET / HTTP/1.1\" 200 -\r\n",
      "127.0.0.1 - - [13/Jan/2024 13:33:56] \"GET /static/css/styles.css HTTP/1.1\" 200 -\r\n",
      "127.0.0.1 - - [13/Jan/2024 13:33:56] \"GET /static/css/docs_det.css HTTP/1.1\" 200 -\r\n",
      "127.0.0.1 - - [13/Jan/2024 13:33:56] \"GET /static/js/category_bubble.js HTTP/1.1\" 200 -\r\n",
      "127.0.0.1 - - [13/Jan/2024 13:33:56] \"GET /static/js/cluster_bubble.js HTTP/1.1\" 200 -\r\n",
      "127.0.0.1 - - [13/Jan/2024 13:33:57] \"GET /static/data/cluster_details.json HTTP/1.1\" 200 -\r\n",
      "127.0.0.1 - - [13/Jan/2024 13:33:57] \"GET /static/data/docs_details.json HTTP/1.1\" 200 -\r\n",
      "127.0.0.1 - - [13/Jan/2024 13:33:57] \"GET /static/data/category_details.json HTTP/1.1\" 200 -\r\n",
      "127.0.0.1 - - [13/Jan/2024 13:34:16] \"GET /cat_details?category=QUEER%20VOICES HTTP/1.1\" 200 -\r\n",
      "127.0.0.1 - - [13/Jan/2024 13:34:16] \"GET /static/css/details.css HTTP/1.1\" 200 -\r\n",
      "127.0.0.1 - - [13/Jan/2024 13:34:16] \"\u001B[36mGET /static/data/category_details.json HTTP/1.1\u001B[0m\" 304 -\r\n",
      "127.0.0.1 - - [13/Jan/2024 13:34:31] \"GET /clu_details?cluster=13 HTTP/1.1\" 200 -\r\n",
      "127.0.0.1 - - [13/Jan/2024 13:34:31] \"\u001B[36mGET /static/css/details.css HTTP/1.1\u001B[0m\" 304 -\r\n",
      "127.0.0.1 - - [13/Jan/2024 13:34:31] \"\u001B[36mGET /static/data/cluster_details.json HTTP/1.1\u001B[0m\" 304 -\r\n",
      "127.0.0.1 - - [13/Jan/2024 13:34:56] \"GET /clu_details?cluster=30 HTTP/1.1\" 200 -\r\n",
      "127.0.0.1 - - [13/Jan/2024 13:34:56] \"\u001B[36mGET /static/css/details.css HTTP/1.1\u001B[0m\" 304 -\r\n",
      "127.0.0.1 - - [13/Jan/2024 13:34:56] \"\u001B[36mGET /static/data/cluster_details.json HTTP/1.1\u001B[0m\" 304 -\r\n",
      "127.0.0.1 - - [13/Jan/2024 13:36:09] \"GET /clu_details?cluster=12 HTTP/1.1\" 200 -\r\n",
      "127.0.0.1 - - [13/Jan/2024 13:36:10] \"\u001B[36mGET /static/css/details.css HTTP/1.1\u001B[0m\" 304 -\r\n",
      "127.0.0.1 - - [13/Jan/2024 13:36:10] \"\u001B[36mGET /static/data/cluster_details.json HTTP/1.1\u001B[0m\" 304 -\r\n",
      "127.0.0.1 - - [13/Jan/2024 13:36:56] \"GET /cat_details?category=WOMEN HTTP/1.1\" 200 -\r\n",
      "127.0.0.1 - - [13/Jan/2024 13:36:56] \"\u001B[36mGET /static/css/details.css HTTP/1.1\u001B[0m\" 304 -\r\n",
      "127.0.0.1 - - [13/Jan/2024 13:36:56] \"\u001B[36mGET /static/data/category_details.json HTTP/1.1\u001B[0m\" 304 -\r\n",
      "127.0.0.1 - - [13/Jan/2024 13:37:51] \"GET /clu_details?cluster=17 HTTP/1.1\" 200 -\r\n",
      "127.0.0.1 - - [13/Jan/2024 13:37:51] \"\u001B[36mGET /static/css/details.css HTTP/1.1\u001B[0m\" 304 -\r\n",
      "127.0.0.1 - - [13/Jan/2024 13:37:51] \"\u001B[36mGET /static/data/cluster_details.json HTTP/1.1\u001B[0m\" 304 -\r\n",
      "^C\r\n"
     ]
    }
   ],
   "source": [
    "!FLASK_APP=flask_app.py flask run --port=5001"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e52bc95db06dbf35",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## The home page of the web application has three tabs:\n",
    "   1. News Articles: shows the news headlines, their details (link, date, authors, and short description) and the corresponding keyword cloud. Details can be shown by clicking on the news headline. This tab is the default tab.\n",
    "      \n",
    "   2. Categories: shows a bubble chart of the categories. The size of each bubble represents the number of articles in the category. When clicking on a bubble, it directs to the category page, showing all the articles in the category and their keywords in two different tabs. When clicking on a news headline, it directs to the news article page.\n",
    "      \n",
    "   3. Clusters: shows a bubble chart of the clusters. The size of each bubble represents the number of articles in the cluster. When clicking on a bubble, it directs to the cluster page, showing all the articles in the cluster and their keywords in two different tabs. When clicking on a news headline, it directs to the news article page.\n",
    " \n",
    "Notes:\n",
    "1. It might take a few seconds to load the home page because it loads the data from the json files.\n",
    "2. For the articles keywords cloud, only a maximum of 20 keywords are shown, to reduce the exported json file size, and thus the loading time."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9935ddd21f386ebe",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Below are some screenshots of the web application: \n",
    " \n",
    "\n",
    "### Home page - News Articles tab (default tab)\n",
    " ![screenshots/home_page_article_list.png](screenshots/home_page_article_list.png)\n",
    " \n",
    "### Home page - Article details\n",
    " ![screenshots/article_details.png](screenshots/article_details.png)\n",
    "\n",
    "### Home page - Categories tab\n",
    " ![screenshots/categories_page.png](screenshots/categories_page.png)\n",
    "\n",
    "### Home page - Clusters tab\n",
    " ![screenshots/clusters_page.png](screenshots/clusters_page.png)\n",
    "\n",
    "### Category page - Articles tab\n",
    " ![screenshots/category_article_list.png](screenshots/category_article_list.png)\n",
    "\n",
    "### Category page - Keywords tab\n",
    "![screenshots/category_wordcloud.png](screenshots/category_wordcloud.png)\n",
    "\n",
    "### Cluster page - Articles tab\n",
    "![screenshots/cluster_article_list.png](screenshots/cluster_article_list.png)\n",
    "\n",
    "### Cluster page - Keywords tab\n",
    "![screenshots/cluster_wordcloud.png](screenshots/cluster_wordcloud.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f9a3d1275fd605",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
